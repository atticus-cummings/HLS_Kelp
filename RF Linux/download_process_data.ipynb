{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "import csv\n",
    "import earthaccess\n",
    "\n",
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import binary_dilation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as mcolors\n",
    "from rasterio.errors import RasterioIOError\n",
    "import csv\n",
    "from skimage import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import sys\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "import shutil\n",
    "import pickle\n",
    "import cupy as cp\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_path = '/mnt/c/Users/attic/HLS_Kelp/maps/Isla_Vista_Kelp.geojson'\n",
    "\n",
    "load_num = -1 #sets number of granules to load, this should generally be >> than num_download;  -1 loads all \n",
    "specific_tile = True #set true if you only want specific tile \n",
    "retrain = False\n",
    "reclassify = True #Reclassify previously classified images\n",
    "show_image = True\n",
    "save_final_data = True\n",
    "save_to_path = '/mnt/c/Users/attic/HLS_Kelp/imagery/' # + tile_processed\n",
    "num_classify =150\n",
    "\n",
    "tile = '11SKU'\n",
    "location = 'Isla_Vista_Kelp'\n",
    "cloud_cover_threshold = .4\n",
    "version = 1\n",
    "temporal = (\"2019-8-01T00:00:00\", \"2020-1-01T00:00:00\") #\n",
    "dem_path = '/mnt/c/Users/attic/HLS_Kelp/imagery/Socal_DEM.tiff'\n",
    "rf_path = r'/mnt/c/users/attic/hls_kelp/random_forest/cu_rf3'\n",
    "sample_geotiff_path = '/mnt/c/Users/attic/HLS_Kelp/imagery/Isla_Vista_Kelp/11SKU/HLS.L30.T11SKU.2018234T183336.v2.0/HLS.L30.T11SKU.2018234T183336.v2.0.B03.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field = gp.read_file(geojson_path)\n",
    "bbox = tuple(list(field.total_bounds))\n",
    "bbox #Display coordinate bounds\n",
    "with open(geojson_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "# Extract the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search for satellite data from  Landsat 30m and Sentinel 30m\n",
    "results = earthaccess.search_data(\n",
    "    short_name=['HLSL30','HLSS30'],\n",
    "    bounding_box=bbox,\n",
    "    temporal=temporal,\n",
    "     cloud_cover=0, #Determine cloud cover\n",
    "    count=load_num\n",
    ")\n",
    "\n",
    "#print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = os.path.join(os.getcwd(),(f'/mnt/c/Users/attic/HLS_Kelp/imagery{location}'))\n",
    "temp_folder = os.path.join(os.path.join(folder_path),'temp')\n",
    "\n",
    "## ======= create location folder path ======= ##\n",
    "if not os.path.isdir(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "if os.path.isdir(temp_folder):\n",
    "    shutil.rmtree(temp_folder)\n",
    "os.mkdir(temp_folder)\n",
    "iterations = 0\n",
    "\n",
    "### ==================== Load RF Classifier ================== ###\n",
    "\n",
    "with open(rf_path, 'rb') as f:\n",
    "    cu_rf = pickle.load(f)\n",
    "\n",
    "### ==================== Create DEM mask ====================  ####\n",
    "with rasterio.open(sample_geotiff_path) as dst:\n",
    "       \n",
    "    hls = dst.read()\n",
    "    dem = rasterio.open(dem_path)\n",
    "    if (dem.crs != dst.crs):\n",
    "        reprojected_dem = np.zeros((hls.shape[1], hls.shape[2]), dtype=hls.dtype)\n",
    "        reproject(\n",
    "            source=dem.read(),\n",
    "            destination=reprojected_dem,\n",
    "            src_transform=dem.transform,\n",
    "            src_crs=dem.crs,\n",
    "            dst_transform=dst.transform,\n",
    "            dst_crs=dst.crs,\n",
    "            resampling=Resampling.bilinear)\n",
    "    hls_flat = np.squeeze(hls, axis=0)   \n",
    "\n",
    "if not reprojected_dem.any():\n",
    "    print(\"Something failed, you better go check...\")\n",
    "    sys.exit()\n",
    "else:\n",
    "    struct = np.ones((5,5))\n",
    "    land_mask = binary_dilation(reprojected_dem > 0, structure = struct)\n",
    "    ocean_mask = binary_dilation(reprojected_dem < -60 , structure = struct)\n",
    "    full_mask = land_mask + ocean_mask\n",
    "    # plt.figure(figsize=(6, 6))\n",
    "    # plt.imshow(land_mask, cmap='gray')\n",
    "    # plt.show()    \n",
    "    \n",
    "print(\"Bathymetry and landmask built. Beginning individual granule processing\")\n",
    "\n",
    "for i, granule in enumerate(results):\n",
    "    if(iterations >num_classify):\n",
    "        break\n",
    "    if os.path.isdir(temp_folder):\n",
    "        shutil.rmtree(temp_folder)\n",
    "    os.mkdir(temp_folder)\n",
    "    ## ======= Parse metadata ======= ##\n",
    "    json_str = json.dumps(granule.__dict__)\n",
    "    metadata = json.loads(json_str) \n",
    "    meta = metadata['render_dict']['meta']\n",
    "    name = meta['native-id']\n",
    "\n",
    "    #For some reason, attributes are parsed into a list in the HLS metadata. This reformats it into a dictionary.\n",
    "    attributes_list = metadata['render_dict']['umm']['AdditionalAttributes']\n",
    "\n",
    "    attributes = {attr['Name']: attr['Values'][0] for attr in attributes_list}\n",
    "    #print(attributes['MGRS_TILE_ID'])\n",
    "    tile_type = attributes['MGRS_TILE_ID']\n",
    "    if(int(attributes['CLOUD_COVERAGE']) > 50): #Reject granules with large cloud cover, for now\n",
    "        print(\"Overall Cloud coverage >50%\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "    time = attributes['SENSING_TIME']\n",
    "    tile_folder = f\"{tile_type}_Classified_v{version}\"\n",
    "    if specific_tile and not tile_type == tile:\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "    ## ======= Create file directory, if needed  ======= ##\n",
    "    tile_path = os.path.join(folder_path,tile_folder)\n",
    "    if not os.path.isdir(tile_path):\n",
    "         os.mkdir(tile_path)\n",
    "\n",
    "    ## ======= download granule ======= ##\n",
    "    with open(os.devnull, 'w') as f, redirect_stdout(f):\n",
    "        downloadPath = earthaccess.download(granule, temp_folder)\n",
    "    \n",
    "    print(f'{name} Downloaded')\n",
    "\n",
    "\n",
    "### ====================  Begin processing each file  ====================  ####\n",
    "\n",
    "    print(f\"Beginning {name} processing\")\n",
    "\n",
    "    ##==========Select Granule and Get File Names==========##\n",
    "\n",
    "    # Check sensor type and define bands for L8 and S2\n",
    "    \n",
    "    files = os.listdir(temp_folder)\n",
    "    file_data = name.split('.')\n",
    "    sensor = file_data[1]\n",
    "    if(sensor == 'L30'):\n",
    "        sensor_bands = ['B02','B03','B04','B05','B06','B07'] #2,3,4,5,6,7]\n",
    "    else:\n",
    "        sensor_bands = ['B02','B03','B04','B8A','B11','B12']\n",
    "    pattern = re.compile(r'\\.(' + '|'.join(sensor_bands) + r')\\.tif$')\n",
    "\n",
    "# Get File names\n",
    "    img_files = [f for f in files if re.search(pattern, f)]\n",
    "    f_mask = [f for f in files if re.search(r'Fmask\\.tif$', f)]\n",
    "    if not f_mask:\n",
    "        print(f\"Invalid granule: {name}\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "    if not len(img_files)  == 6:\n",
    "        print(f\"incomplete file download: {name}\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "\n",
    "    img_bands = []\n",
    "\n",
    "##==========Fmask Cloud mask==========##\n",
    "    #bitwise operations are weird. Far outside my comfort zone. Need to take CS33 first.........\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(temp_folder,f_mask[0])) as fmask:\n",
    "            qa_band = fmask.read(1)\n",
    "        qa_bit = (1 << 1) - 1\n",
    "        qa_cloud_mask = ((qa_band >> 1) & qa_bit) == 1  # Bit 1 for cloud\n",
    "        qa_adjacent_to_cloud_mask = ((qa_band >> 2) & qa_bit) == 1  # Bit 2 for cloud adjacent\n",
    "        qa_cloud_shadow = ((qa_band >> 3) & qa_bit) == 1 \n",
    "        qa_ice = ((qa_band >> 4) & qa_bit) == 1 \n",
    "        #qa_water = ((qa_band >> 5) & qa_bit) == 1\n",
    "        qa_aerosol = (((qa_band >> 6) & 1) == 1) & (((qa_band >> 7) & 1) == 1)\n",
    "        cloud_mask = qa_cloud_mask | qa_cloud_shadow | qa_ice | qa_aerosol #Mask out Clouds and cloud-adjacent pixels \n",
    "        cloud_mask_2D = cloud_mask.reshape(-1).T\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Error reading file {file} in granule {name}: {e}\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue  # Skip to the next granule if a file cannot be read\n",
    "    #may not be necessary to mask out the cloud-adjacent pixels \n",
    "\n",
    "##========== Determine percentage of ocean covered by clouds ==========##\n",
    "    cloud_land_mask = cloud_mask | land_mask\n",
    "    cloud_but_not_land_mask = cloud_mask & ~land_mask\n",
    "    num_pixels_cloud_not_land = np.count_nonzero(cloud_but_not_land_mask)\n",
    "    num_pixels_not_land = np.count_nonzero(~land_mask)\n",
    "    percent_cloud_covered = num_pixels_cloud_not_land/num_pixels_not_land\n",
    "    if(percent_cloud_covered > cloud_cover_threshold):\n",
    "        print(f\"Percent clouds greater than threshold: {percent_cloud_covered}. Moving to next granule...\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "    print(f'{name} Percent cloud covered: {percent_cloud_covered}')\n",
    "    \n",
    " ##==========Create stacked np array, Apply landmask==========##\n",
    "    try:\n",
    "        for file in img_files:\n",
    "            with rasterio.open(os.path.join(temp_folder, file)) as src:\n",
    "                img_bands.append(np.where(cloud_land_mask, 0, src.read(1)))  # Create image with the various bands\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Error reading file {file} in granule {name}: {e}\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue  # Skip to the next granule if a file cannot be read\n",
    "    img = np.stack(img_bands, axis=0)\n",
    "    n_bands, height, width = img.shape\n",
    "    img_2D = img.reshape(img.shape[0], -1).T #classifier takes 2D array of band values for each pixel \n",
    "\n",
    " ##========== Normalize multi-spectral data ==========##\n",
    "\n",
    "    img_sum = img_2D.sum(axis=1)\n",
    "    epsilon = 1e-10  \n",
    "    img_2D_nor = np.divide(img_2D, img_sum[:, None] + epsilon, where=(img_sum[:, None] != 0))\n",
    "    img_2D_nor = (img_2D_nor * 255).astype(np.uint8)\n",
    "\n",
    " ##========== Classify Image with random forest ==========##\n",
    "    print(\"Beginning kelp classification\")\n",
    "    img_data = cudf.DataFrame(img_2D_nor)\n",
    "    img_data = img_data.astype(np.float32)\n",
    "\n",
    "    classification_pred = cu_rf.predict(img_data)\n",
    "    classified_img = classification_pred.values_host.reshape(width,height)\n",
    "\n",
    "    print(\"Classification finished\")\n",
    " ##========== Display image, if asked to ==========##\n",
    "    if show_image:\n",
    "        print(file)\n",
    "        plt.figure(figsize=(25, 25)) \n",
    "        plt.subplot(2, 1, 1)  \n",
    "        plt.imshow(classified_img)#[2700:3400, 600:2000])\n",
    "        plt.colorbar()\n",
    "        plt.title(file)\n",
    "        r_nor = img_2D_nor[:,2].reshape((height, width))\n",
    "        g_nor = img_2D_nor[:,1].reshape((height, width))\n",
    "        b_nor = img_2D_nor[:,0].reshape((height, width))\n",
    "        rgb_nor = np.stack([r_nor,g_nor,b_nor], axis=-1)  \n",
    "        rgb_cropped = rgb_nor#[2700:3400, 600:2000]\n",
    "        plt.subplot(2, 1, 2) \n",
    "        plt.imshow(rgb_cropped)\n",
    "        plt.title(\"RGB Cropped Image\")\n",
    "        #plt.colorbar()\n",
    "        plt.show()\n",
    " ##========== Prep for Mesma ==========##\n",
    "    ocean_dilation = np.ones((50,50)) #Struct for dilation (increase to enlarge non-ocean mask) larger --> takes longer\n",
    "    kelp_dilation = np.ones((20,20))\n",
    "    kelp_shrink = np.ones((1,1))\n",
    "    kelp_mask  = []\n",
    "    ocean_mask = []\n",
    "    print(\"Masking image for MESMA\")\n",
    "##========== Create mask for kelp and ocean ==========##\n",
    "    land_dilated = np.where(classified_img == 3, True, False)\n",
    "    clouds_dilated = np.where(classified_img == 2, True, False)\n",
    "    land_dilated = binary_dilation(land_dilated, structure=ocean_dilation)\n",
    "\n",
    "    ocean_dilated = land_dilated | clouds_dilated \n",
    "    #\n",
    "    kelp_dilated = np.where(classified_img == 0, True, False) #This is expanding hte kelp_mask so the TF is reversed\n",
    "    kelp_dilated = ~binary_dilation(~kelp_dilated, structure=kelp_shrink)\n",
    "    kelp_dilated = binary_dilation(kelp_dilated,structure=kelp_dilation) #I may not want to do this. we'll see\n",
    "    for i in range(4):\n",
    "        kmask = np.where(kelp_dilated == True, img[i],np.nan)\n",
    "        omask = np.where(ocean_dilated == False, img[i], np.nan)\n",
    "        kelp_mask.append(kmask)\n",
    "        ocean_mask.append(omask)\n",
    "\n",
    "    kelp_mask = np.array(kelp_mask)\n",
    "    ocean_mask = np.array(ocean_mask)\n",
    "\n",
    "    rgb_nor = np.stack([ocean_mask[2]/600,ocean_mask[0]/600,ocean_mask[1]/600], axis=-1)\n",
    "    rgb_nor_cropped = rgb_nor\n",
    "    #print(kelp_mask)\n",
    "    rgb_nor_cropped = np.ma.masked_where(np.isnan(rgb_nor_cropped), rgb_nor_cropped)\n",
    "    print(\"Generated final kelp & ocean mask\")\n",
    "##========== Display masked image, if asked to ==========##\n",
    "    if show_image:\n",
    "        display_image = kelp_mask[1]#,2500:3500,800:1800]\n",
    "        plt.figure(figsize=(30, 30), dpi=200)\n",
    "        plt.imshow(display_image, alpha=1)\n",
    "        plt.imshow(rgb_nor_cropped, alpha=1)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    " ##========== Prepare kelp and ocean endmembers ==========##\n",
    "    print(\"Gathering Endmembers\")\n",
    "    ocean_EM_stack = []\n",
    "    kelp_EM = [459, 556, 437, 1227]\n",
    "\n",
    "    n_bands, height, width = kelp_mask.shape\n",
    "    ocean_EM_n = 0\n",
    "    ocean_data = ocean_mask.reshape(ocean_mask.shape[0], -1)\n",
    "    kelp_data = kelp_mask.reshape(kelp_mask.shape[0],-1)\n",
    "\n",
    "    nan_columns = np.isnan(ocean_data).all(axis=0)  # Remove columns with nan \n",
    "\n",
    "\n",
    "\n",
    "    filtered_ocean = ocean_data[:, ~nan_columns]\n",
    "    if(len(filtered_ocean[0,:]) < 100):\n",
    "    \n",
    "        print(f\"Insufficient number of ocean pixels: {len(filtered_ocean[0,:])}\")\n",
    "        shutil.rmtree(temp_folder)\n",
    "        continue\n",
    "\n",
    "    for i in range(30):\n",
    "        index = random.randint(0,len(filtered_ocean[0])-1)\n",
    "        ocean_EM_stack.append(filtered_ocean[:,index])\n",
    "    ocean_EM = np.stack(ocean_EM_stack, axis=1)\n",
    "    #print(ocean_EM_array)\n",
    "\n",
    "    average_val = np.nanmean(filtered_ocean, axis=1)\n",
    "    average_endmember = np.nanmean(ocean_EM, axis=1)\n",
    "    print(f\"average EM Val: {average_endmember}\")\n",
    "    print(f\"average    Val: {average_val}\")\n",
    "\n",
    "   \n",
    "    kelp_mask = cp.asarray(kelp_mask)\n",
    "    ocean_EM = cp.asarray(ocean_EM)\n",
    "    kelp_EM = cp.asarray(kelp_EM)\n",
    "    kelp_data = cp.asarray(kelp_data)\n",
    "\n",
    "    frac1 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    frac2 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    rmse = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    print(rmse.shape)\n",
    " ###========== Start MESMA ==========##\n",
    "    print(\"Running MESMA\")\n",
    "    for k in range(30):\n",
    "        B = cp.column_stack((ocean_EM[:, k], kelp_EM))\n",
    "        U, S, Vt = cp.linalg.svd(B, full_matrices=False)\n",
    "        IS = Vt.T / S\n",
    "        em_inv = IS @ U.T\n",
    "        F = em_inv @ kelp_data\n",
    "        model = (F.T @ B.T).T\n",
    "        resids = (kelp_data - model) / 10000\n",
    "        rmse[:, :, k] = cp.sqrt(cp.mean(resids**2, axis=0)).reshape(height, width)\n",
    "        frac1[:, :, k] = F[0, :].reshape(height, width)\n",
    "        frac2[:, :, k] = F[1, :].reshape(height, width)\n",
    "\n",
    "    print(\"MESMA Complete, building final image\")\n",
    "\n",
    "    minVals = cp.nanmin(rmse, axis=2)\n",
    "    PageIdx = cp.nanargmin(rmse, axis=2)\n",
    "    rows, cols = cp.meshgrid(cp.arange(rmse.shape[0]), cp.arange(rmse.shape[1]), indexing='ij')\n",
    "    Zindex = cp.ravel_multi_index((rows, cols, PageIdx), dims=rmse.shape)\n",
    "    Mes2 = frac2.ravel()[Zindex]\n",
    "    Mes2 = Mes2.T\n",
    "    Mes2 = -0.229 * Mes2**2 + 1.449 * Mes2 - 0.018 #Landsat mesma corrections \n",
    "    Mes2 = cp.clip(Mes2, 0, None)  # Ensure no negative values\n",
    "    Mes2 = cp.round(Mes2 * 100).astype(cp.int16)\n",
    "    if show_image:\n",
    "        kelp_img = cp.asnumpy(kelp_mask)\n",
    "        Mes_array = cp.asnumpy(Mes2).T\n",
    "        Mes_array_vis = np.where(Mes_array == 0, np.nan, Mes_array)\n",
    "        kelp_vis = np.where(kelp_img == 0, np.nan, kelp_img)\n",
    "        plt.figure(figsize=(20, 20), dpi=200)\n",
    "        plt.imshow(rgb_nor[1,2800:3100,800:1400])\n",
    "        plt.imshow(kelp_img[1,2800:3100,800:1400] , cmap='Greys', alpha=1)\n",
    "        plt.imshow(Mes_array_vis[2800:3100,800:1400], alpha=1)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    if save_final_data:\n",
    "        num_bands = 6\n",
    "        data_type = rasterio.int16\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'count': 6,  # one band  B02, B03, B04, and B05, classified (Blue, Green, Red, and NIR).\n",
    "            'dtype': data_type,  # assuming binary mask, adjust dtype if needed\n",
    "            'crs': src.crs,\n",
    "            'transform': src.transform,\n",
    "            'nodata': 0  # assuming no data is 0\n",
    "        }\n",
    "        if not os.path.isdir(os.path.join(save_to_path,tile_type)):\n",
    "            os.mkdir(os.path.join(save_to_path,tile_type))\n",
    "        img_path = os.path.join(save_to_path,tile_type,f'{name}_processed.tif')\n",
    "\n",
    "        # Write the land mask array to GeoTIFF\n",
    "        with rasterio.open(img_path, 'w', **profile) as dst:\n",
    "                dst.write(img[0].astype(data_type), 1)\n",
    "                dst.write(img[1].astype(data_type), 2)\n",
    "                dst.write(img[2].astype(data_type), 3)\n",
    "                dst.write(img[3].astype(data_type), 4)\n",
    "                dst.write(classified_img.astype(data_type), 5)\n",
    "                dst.write(Mes_array.astype(data_type), 6)\n",
    "                \n",
    "        iterations = iterations + 1\n",
    "        print(f\"{iterations}/{len(results)}\")\n",
    "\n",
    "    print(f\"{name} Processing complete.\")\n",
    "    shutil.rmtree(temp_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls-linux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
