{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = False\n",
    "rf_file = 'cu_rf9'\n",
    "reclassify = True #Reclassify previously classified images\n",
    "show_image = True\n",
    "num_classify = 20\n",
    "classified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_classified_S30'\n",
    "unclassified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_prepped_v3'\n",
    "unclassified_files = os.listdir(unclassified_path)\n",
    "rf_path = r'/mnt/c/users/attic/hls_kelp/random_forest/'\n",
    "training_path = r'/mnt/c/Users/attic/HLS_Kelp/imagery/RF_training_v6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "if retrain:\n",
    "    logging.info(\"Retraining model...\")\n",
    "    training_files = os.listdir(training_path)\n",
    "    filtered_files = [file for file in training_files if not file.endswith('.xml')]\n",
    "    training_data = []\n",
    "\n",
    "    for file in filtered_files:\n",
    "        try:\n",
    "            logging.info(f\"Processing file: {file}\")\n",
    "            # file_data = file.split('.')\n",
    "            # sensor = file_data[1]\n",
    "            # if sensor == 'L30':\n",
    "            #     logging.info(f\"Skipping file: {file} due to sensor type\")\n",
    "            #     continue\n",
    "\n",
    "            with rasterio.open(os.path.join(training_path, file)) as src:\n",
    "                training_img = src.read()\n",
    "            logging.info(f\"Read image shape: {training_img.shape}\")\n",
    "            \n",
    "            training_img = training_img[:, 2600:3600, :]\n",
    "            file_data = training_img.reshape(training_img.shape[0], -1)\n",
    "            training_data.append(file_data)\n",
    "            logging.info(f\"Processed file {file} successfully.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Combining training data...\")\n",
    "        combined_training_data = np.hstack(training_data)\n",
    "        logging.info(f\"Combined training data shape: {combined_training_data.shape}\")\n",
    "\n",
    "        logging.info(\"Creating cuDF DataFrame...\")\n",
    "        df = cudf.DataFrame(combined_training_data.T)\n",
    "        X = df.iloc[:, :-1].astype('float32')\n",
    "        y = df.iloc[:, -1].astype('float32')\n",
    "        \n",
    "        logging.info(\"Splitting data into train and test sets...\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.95, random_state=42)\n",
    "        \n",
    "        logging.info(\"Setting Random Forest parameters...\")\n",
    "        cu_rf_params = {\n",
    "            'n_estimators': 100,  # Increase number of trees\n",
    "            'max_depth': 150,     # Increase maximum depth\n",
    "            'n_bins': 40,         # Increase number of bins\n",
    "            'n_streams': 6     # Adjust parallel streams based on GPU capability\n",
    "        }\n",
    "\n",
    "        logging.info(\"Initializing Random Forest classifier...\")\n",
    "        cu_rf = cuRF(**cu_rf_params)\n",
    "        \n",
    "        logging.info(\"Fitting model...\")\n",
    "        cu_rf.fit(X_train, y_train)\n",
    "        \n",
    "        logging.info(\"Predicting test data...\")\n",
    "        y_pred = cu_rf.predict(X_test)\n",
    "        \n",
    "        accuracy = cuml.metrics.accuracy_score(y_test, y_pred)\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during training: {e}\")\n",
    "\n",
    "else:\n",
    "    logging.info(\"Retrain set to False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if retrain: \n",
    "    if not os.path.isdir(rf_path):\n",
    "        os.mkdir(rf_path)\n",
    "    with open(os.path.join(rf_path, rf_file), 'wb') as f:\n",
    "        pickle.dump(cu_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not retrain:\n",
    "    with open(os.path.join(rf_path,rf_file), 'rb') as f:\n",
    "        cu_rf = pickle.load(f)\n",
    "\n",
    "for i, file in enumerate(unclassified_files[6:50]):\n",
    "    if(i > num_classify):\n",
    "         break\n",
    "    file_data = file.split('.')\n",
    "    sensor = file_data[1]\n",
    "    # if(sensor != 'L30'):\n",
    "    #      continue\n",
    "    file_name = file.split('_')\n",
    "    if not reclassify and os.path.isfile(os.path.join(classified_path, f'{file_name[0]}_kelp_classified.tif')):\n",
    "        print(f\"{file} already classified\")\n",
    "        continue\n",
    "    file_img =[]\n",
    "    with rasterio.open(os.path.join(unclassified_path,file)) as src:\n",
    "        file_img = src.read(indexes=[1, 2, 3, 4, 5, 6])\n",
    "        img = np.stack(file_img, axis=0)\n",
    "        n_bands, height, width = img.shape\n",
    "        img_2D = img.reshape(img.shape[0], -1).T #classifier takes 2D array of band values for each pixel \n",
    "    #normalized_img_bands = np.column_stack((img_2D, cloud_mask_2D))\n",
    " ##========== Normalize multi-spectral data ==========##\n",
    "        img_sum = img_2D.sum(axis=1)\n",
    "        epsilon = 1e-10  \n",
    "        img_2D_nor = np.divide(img_2D, img_sum[:, None] + epsilon, where=(img_sum[:, None] != 0))\n",
    "        img_2D_nor = (img_2D_nor * 255).astype(np.uint8)\n",
    "        #img_normalized = img_2D_normalized.reshape((height, width))\n",
    "            # img_sum_nonzero = np.where(img_sum == 0, 1, img_sum)\n",
    "            # img_2D_normalized = img_2D / img_sum_nonzero[:, None] #divide value by sum of pixel band values\n",
    "            # print(img_2D_normalized.shape)\n",
    "            # img_2D_normalized = (img_2D_normalized * 255)\n",
    "            # img_2D_normalized = img_2D_normalized.astype(np.uint8)\n",
    "\n",
    "        #img_data= file_img.reshape(file_img.shape[0], -1).T\n",
    "        img_data = cudf.DataFrame(img_2D_nor)\n",
    "        img_data = img_data.astype(np.float32)\n",
    "        kelp_pred = cu_rf.predict(img_data)\n",
    "        kelp_img = kelp_pred.values_host.reshape(width,height)\n",
    "        if show_image:\n",
    "            print(file)\n",
    "            plt.figure(figsize=(25, 25)) \n",
    "            plt.subplot(2, 1, 1)  \n",
    "            plt.imshow(kelp_img)#[2700:3400, 600:2000])\n",
    "            plt.title(file)\n",
    "            r_nor = img_2D_nor[:,2].reshape((height, width))\n",
    "            g_nor = img_2D_nor[:,1].reshape((height, width))\n",
    "            b_nor = img_2D_nor[:,0].reshape((height, width))\n",
    "            rgb_nor = np.stack([r_nor,g_nor,b_nor], axis=-1)  \n",
    "            rgb_cropped = rgb_nor#[2700:3400, 600:2000]\n",
    "            plt.subplot(2, 1, 2) \n",
    "            plt.imshow(rgb_cropped)\n",
    "            plt.title(\"RGB Cropped Image\")\n",
    "            #plt.colorbar()\n",
    "            plt.show()\n",
    "        data_type = rasterio.int16\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'count': 5,  # one band  B02, B03, B04, and B05, classified (Blue, Green, Red, and NIR).\n",
    "            'dtype': data_type,  # assuming binary mask, adjust dtype if needed\n",
    "            'crs': src.crs,\n",
    "            'transform': src.transform,\n",
    "            'nodata': 0  # assuming no data is 0\n",
    "        }\n",
    "        # Write the land mask array to GeoTIFF\n",
    "        if not os.path.isdir(classified_path):\n",
    "            os.mkdir(classified_path)\n",
    "        with rasterio.open(os.path.join(classified_path, f'{file_name[0]}_kelp_classified.tif'), 'w', **profile) as dst:\n",
    "                dst.write(file_img[0].astype(data_type), 1)\n",
    "                dst.write(file_img[1].astype(data_type), 2)\n",
    "                dst.write(file_img[2].astype(data_type), 3)\n",
    "                dst.write(file_img[3].astype(data_type), 4)\n",
    "                dst.write(kelp_img.astype(rasterio.uint8), 5)\n",
    "        print(f'{i+1} / {len(unclassified_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cu_rf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
