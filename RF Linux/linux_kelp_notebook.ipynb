{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "#from scipy.ndimage import binary_dilation, uniform_filter\n",
    "from rasterio.errors import RasterioIOError\n",
    "import csv\n",
    "from skimage import io\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import gc\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.model_selection import train_test_split\n",
    "from scipy.stats import randint\n",
    "from cupyx.scipy.ndimage import binary_dilation, convolve\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import cupy as cp\n",
    "import random\n",
    "\n",
    "retrain = False\n",
    "reclassify = False #Reclassify previously classified images\n",
    "show_image = True\n",
    "\n",
    "#classified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_classified_cuML'\n",
    "save_final_data = True\n",
    "save_to_path = '/mnt/c/Users/attic/HLS_Kelp/imagery/Isla_vista_kelp_2018/processed'\n",
    "tile = '11SKU'\n",
    "location = 'Isla_Vista_Kelp_2018'\n",
    "cloud_cover_threshold = .8\n",
    "#save_mask = True\n",
    "#save_classification = True\n",
    "#remask = False\n",
    "path = os.path.join(r'/mnt/c/Users/attic/HLS_Kelp/imagery',location,tile)\n",
    "dem_path = r'/mnt/c/Users/attic/HLS_Kelp/imagery/Socal_DEM.tiff'\n",
    "rf_path = r'/mnt/c/users/attic/hls_kelp/random_forest/cu_rf7_S30'\n",
    "num_iterations = 1000\n",
    "#unclassified_path = r'/mnt/c/users/attic/hls_kelp/imagery/rf_prepped_v2'\n",
    "#unclassified_files = os.listdir(unclassified_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_granule_data(path):\n",
    "    granules = os.listdir(path)\n",
    "    for item in granules:\n",
    "        if os.path.isdir(os.path.join(path, item)):\n",
    "            img_path = os.path.join(path, item)\n",
    "            granule = item\n",
    "            break\n",
    "    files = os.listdir(img_path)\n",
    "    return img_path, granule, files\n",
    "\n",
    "\n",
    "def get_sensor_bands(granule):\n",
    "    file_data = granule.split('.')\n",
    "    sensor = file_data[1]\n",
    "    if sensor == 'L30':\n",
    "        return ['B02', 'B03', 'B04', 'B05', 'B06', 'B07']\n",
    "    else:\n",
    "        return ['B02', 'B03', 'B04', 'B8A', 'B11', 'B12']\n",
    "    \n",
    "def load_rf_classifier(rf_path):\n",
    "    with open(rf_path, 'rb') as f:\n",
    "        cu_rf = pickle.load(f)\n",
    "    return cu_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_granule(img_files, sensor_bands, files, item):\n",
    "    f_mask = [f for f in files if re.search(r'Fmask\\.tif$', f)]\n",
    "    if not f_mask or len(img_files) != len(sensor_bands):\n",
    "        print(f\"Incomplete or invalid granule: {item}\")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_dem_to_hls(dem_path='/mnt/c/Users/attic/HLS_Kelp/imagery/Socal_DEM.tiff', hls_path):\n",
    "    with rasterio.open(hls_path) as dst:\n",
    "        hls = dst.read()\n",
    "        dem = rasterio.open(dem_path)\n",
    "        if dem.crs != dst.crs:\n",
    "            reprojected_dem = np.zeros((hls.shape[1], hls.shape[2]), dtype=hls.dtype)\n",
    "            reproject(\n",
    "                source=dem.read(),\n",
    "                destination=reprojected_dem,\n",
    "                src_transform=dem.transform,\n",
    "                src_crs=dem.crs,\n",
    "                dst_transform=dst.transform,\n",
    "                dst_crs=dst.crs,\n",
    "                resampling=Resampling.bilinear)\n",
    "    return reprojected_dem , hls\n",
    "\n",
    "def generate_land_mask(reprojected_dem, land_dilation=5, show_image=False):\n",
    "    if reprojected_dem.any():\n",
    "        struct = cp.ones((land_dilation, land_dilation))\n",
    "        reprojected_dem_gpu = cp.asarray(reprojected_dem)\n",
    "        land_mask = binary_dilation(reprojected_dem_gpu > 0, structure=struct)\n",
    "        land_mask = cp.asnumpy(land_mask)\n",
    "        if show_image:\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(land_mask, cmap='gray')\n",
    "            plt.show()\n",
    "        return land_mask\n",
    "    else:\n",
    "        print(\"Something failed, you better go check...\")\n",
    "        sys.exit()\n",
    "\n",
    "def create_land_mask(hls_path, dem_path='/mnt/c/Users/attic/HLS_Kelp/imagery/Socal_DEM.tiff'):\n",
    "    reprojected_dem = reproject_dem_to_hls(hls_path, dem_path='/mnt/c/Users/attic/HLS_Kelp/imagery/Socal_DEM.tiff')\n",
    "    return generate_land_mask(reprojected_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesma_mask(\n",
    "    classified_img,\n",
    "    band_data,\n",
    "    ocean_dilation_size=100,  # Struct size for dilation\n",
    "    kelp_neighborhood=5,\n",
    "    min_kelp_count=4,\n",
    "    kelp_dilation_size=15,\n",
    "    variance_window_size=15,\n",
    "    variance_threshold=0.95\n",
    "):\n",
    "    ocean_dilation = cp.ones((ocean_dilation_size, ocean_dilation_size))\n",
    "    structuring_element = cp.ones((kelp_dilation_size, kelp_dilation_size))\n",
    "    \n",
    "    time_st = time.time()\n",
    "    classified_img_gpu = cp.array(classified_img)\n",
    "\n",
    "    kelp_mask = []\n",
    "    ocean_mask = []\n",
    "\n",
    "    time_val = time.time()\n",
    "    land_dilated_gpu = cp.where(classified_img_gpu == 3, True, False)\n",
    "    clouds_dilated_gpu = cp.where(classified_img_gpu == 2, True, False)\n",
    "    land_dilated_gpu = binary_dilation(land_dilated_gpu, structure=ocean_dilation)\n",
    "    print(f'land finished: {time.time()-time_val}')\n",
    "\n",
    "    ocean_dilated_gpu = land_dilated_gpu | clouds_dilated_gpu \n",
    "\n",
    "    def count_true(window):\n",
    "        return cp.sum(window)\n",
    "\n",
    "    kelp_dilated_gpu = cp.where(classified_img_gpu == 0, True, False)  # This is expanding the kelp_mask so the TF is reversed\n",
    "    kernel = cp.ones((kelp_neighborhood, kelp_neighborhood), dtype=cp.int32)\n",
    "\n",
    "    time_val = time.time()\n",
    "    kelp_count_gpu = convolve(kelp_dilated_gpu.astype(cp.int32), kernel, mode='constant', cval=0.0)\n",
    "    print(f'kelp moving average finished: {time.time()-time_val}')\n",
    "\n",
    "    kelp_dilated_gpu = cp.where(((~kelp_dilated_gpu) | (kelp_count_gpu <= min_kelp_count)), 0, 1)  # If there's no kelp, or the kelp count is <=4, set pixel == false\n",
    "    time_val = time.time()\n",
    "    kelp_dilated_gpu = binary_dilation(kelp_dilated_gpu, structure=structuring_element)  # I may not want to do this. we'll see\n",
    "    print(f'kelp dilation finished: {time.time()-time_val}')\n",
    "    time_val = time.time()\n",
    "    for i in range(4):\n",
    "        band_data = img[i ]\n",
    "        band_data_gpu = cp.array(band_data)\n",
    "        \n",
    "        kmask_gpu = cp.where(kelp_dilated_gpu == 1, band_data_gpu, cp.nan)\n",
    "\n",
    "        local_variance_gpu = calculate_local_variance(band_data_gpu, variance_window_size)\n",
    "        max_local_variance = cp.percentile(local_variance_gpu, 100 * variance_threshold)  # threshold variance\n",
    "        # Mask pixels with high variance\n",
    "        variance_mask_gpu = cp.where(local_variance_gpu > max_local_variance, cp.nan, band_data_gpu)\n",
    "        final_omask_gpu = cp.where((ocean_dilated_gpu == True) | cp.isnan(variance_mask_gpu) , cp.nan, band_data_gpu)\n",
    "\n",
    "        kmask = cp.asnumpy(kmask_gpu)\n",
    "        omask = cp.asnumpy(final_omask_gpu)\n",
    "        \n",
    "        kelp_mask.append(kmask)\n",
    "        ocean_mask.append(omask)\n",
    "    print(f'kBand masking and variance masking complete: {time.time()-time_val}')\n",
    "    kelp_mask = np.array(kelp_mask)\n",
    "    ocean_mask = np.array(ocean_mask)\n",
    "    return kelp_mask, ocean_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ocean_endmembers(ocean_mask, print_average=False, n=30, min_pixels=500):\n",
    "    ocean_EM_n = 0\n",
    "    ocean_data = ocean_mask.reshape(ocean_mask.shape[0], -1)\n",
    "    nan_columns = np.isnan(ocean_data).any(axis=0)  # Remove columns with nan \n",
    "   \n",
    "    filtered_ocean = ocean_data[:, ~nan_columns]\n",
    "    if len(filtered_ocean[0,:]) < min_pixels:\n",
    "        print(\"Too few valid ocean end-members\")\n",
    "        print(f\"Skipping img {file}...  :(\")\n",
    "        return False\n",
    "    \n",
    "    for i in range(n):\n",
    "        index = random.randint(0,len(filtered_ocean[0])-1)\n",
    "        ocean_EM_stack.append(filtered_ocean[:,index])\n",
    "    ocean_EM = np.stack(ocean_EM_stack, axis=1)\n",
    "    #print(ocean_EM_array)\n",
    "    if(print_average):\n",
    "        average_val = np.nanmean(filtered_ocean, axis=1)\n",
    "        average_endmember = np.nanmean(ocean_EM, axis=1)\n",
    "        print(f\"average EM Val: {average_endmember}\")\n",
    "        print(f\"average    Val: {average_val}\")\n",
    "    return ocean_EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mesma(kelp_mask, ocean_EM, n=30):\n",
    "    frac1 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], n), cp.nan)\n",
    "    frac2 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], n), cp.nan)\n",
    "    rmse = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], n), cp.nan)\n",
    "    print(rmse.shape)\n",
    "\n",
    "    print(\"Running MESMA\")\n",
    "    for k in range(n):\n",
    "        B = cp.column_stack((ocean_EM[:, k], kelp_EM))\n",
    "        U, S, Vt = cp.linalg.svd(B, full_matrices=False)\n",
    "        IS = Vt.T / S\n",
    "        em_inv = IS @ U.T\n",
    "        F = em_inv @ kelp_data\n",
    "        model = (F.T @ B.T).T\n",
    "        resids = (kelp_data - model) / 10000\n",
    "        rmse[:, :, k] = cp.sqrt(cp.mean(resids**2, axis=0)).reshape(height, width)\n",
    "        frac1[:, :, k] = F[0, :].reshape(height, width)\n",
    "        frac2[:, :, k] = F[1, :].reshape(height, width)\n",
    "\n",
    "    minVals = cp.nanmin(rmse, axis=2)\n",
    "    PageIdx = cp.nanargmin(rmse, axis=2)\n",
    "    rows, cols = cp.meshgrid(cp.arange(rmse.shape[0]), cp.arange(rmse.shape[1]), indexing='ij')\n",
    "    Zindex = cp.ravel_multi_index((rows, cols, PageIdx), dims=rmse.shape)\n",
    "    Mes2 = frac2.ravel()[Zindex]\n",
    "    Mes2 = Mes2.T\n",
    "    Mes2 = -0.229 * Mes2**2 + 1.449 * Mes2 - 0.018 #Landsat mesma corrections \n",
    "    Mes2 = cp.clip(Mes2, 0, None)  # Ensure no negative values\n",
    "    Mes2 = cp.round(Mes2 * 100).astype(cp.int16)\n",
    "    return Mes2, minVals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def create_qa_mask(land_mask, files, ):\n",
    "    f_mask = [f for f in files if re.search(r'Fmask\\.tif$', f)]\n",
    "    if not f_mask:\n",
    "        print(f\"Invalid granule: {item}\")\n",
    "        return False\n",
    "\n",
    "##==========Fmask Cloud mask==========##\n",
    "    #bitwise operations are weird. Far outside my comfort zone. Need to take CS33 first.........\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(img_path,f_mask[0])) as fmask:\n",
    "            qa_band = fmask.read(1)\n",
    "        # qa_bit = (1 << 1) - 1\n",
    "        # qa_cloud_mask = ((qa_band >> 1) & qa_bit) == 1  # Bit 1 for cloud\n",
    "        # qa_adjacent_to_cloud_mask = ((qa_band >> 2) & qa_bit) == 1  # Bit 2 for cloud adjacent\n",
    "        # qa_cloud_shadow = ((qa_band >> 3) & qa_bit) == 1 \n",
    "        # qa_ice = ((qa_band >> 4) & qa_bit) == 1 \n",
    "        # qa_aerosol = (((qa_band >> 6) & 1) == 1) & (((qa_band >> 7) & 1) == 1)\n",
    "        # cloud_mask = qa_cloud_mask | qa_adjacent_to_cloud_mask | qa_cloud_shadow | qa_ice | qa_aerosol#Mask out Clouds and cloud-adjacent pixels \n",
    "        cloud_mask = ((qa_band >> 1) & 1) | ((qa_band >> 2) & 1) | ((qa_band >> 3) & 1) | ((qa_band >> 4) & 1) | (((qa_band >> 6) & 1) & ((qa_band >> 7) & 1))\n",
    "        #cloud_mask_2D = cloud_mask.reshape(-1).T\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Error reading file {file} in granule {item}: {e}\")\n",
    "        return False  # Skip to the next granule if a file cannot be read\n",
    "    #may not be necessary to mask out the cloud-adjacent pixels \n",
    "\n",
    "##========== Determine percentage of ocean covered by clouds ==========##\n",
    "    cloud_land_mask = cloud_mask | land_mask\n",
    "    cloud_but_not_land_mask = cloud_mask & ~land_mask\n",
    "    num_pixels_cloud_not_land = np.count_nonzero(cloud_but_not_land_mask)\n",
    "    num_pixels_not_land = np.count_nonzero(~land_mask)\n",
    "    percent_cloud_covered = num_pixels_cloud_not_land/num_pixels_not_land\n",
    "    # print(f'{granule} Percent cloud covered: {percent_cloud_covered}')\n",
    "    return cloud_land_mask, cloud_but_not_land_mask, percent_cloud_covered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_img(img, flatten=False):\n",
    "    img_2D = img.reshape(img.shape[0], -1).T\n",
    "    img_sum = img_2D.sum(axis=1)\n",
    "    epsilon = 1e-10  \n",
    "    img_2D_nor = np.divide(img_2D, img_sum[:, None] + epsilon, where=(img_sum[:, None] != 0))\n",
    "    img_2D_nor = (img_2D_nor * 255).astype(np.uint8)\n",
    "    if not flatten:\n",
    "        img_data= img_2D_nor.reshape(img_2D_nor.shape[0], -1).T\n",
    "        return img_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "### ==================== Create DEM mask ====================  ####\n",
    "granules = os.listdir(path)\n",
    "for item in granules:\n",
    "    if os.path.isdir(os.path.join(path,item)):\n",
    "        img_path = os.path.join(path,item)\n",
    "        granule = item\n",
    "        break\n",
    "    else:\n",
    "        continue\n",
    "files = os.listdir(img_path)\n",
    "file_data = granule.split('.')\n",
    "sensor = file_data[1]\n",
    "if(sensor == 'L30'):\n",
    "    sensor_bands = ['B02','B03','B04','B05','B06','B07'] #2,3,4,5,6,7]\n",
    "else:\n",
    "    sensor_bands = ['B02','B03','B04','B08A','B11','B12']\n",
    "    \n",
    "pattern = re.compile(r'\\.(' + '|'.join(sensor_bands) + r')\\.tif$')\n",
    "img_files = [f for f in files if re.search(pattern, f)]\n",
    "geotiff_path = os.path.join(img_path, img_files[0])\n",
    "\n",
    "with rasterio.open(geotiff_path) as dst:   \n",
    "    hls = dst.read()\n",
    "\n",
    "    dem = rasterio.open(dem_path)\n",
    "    if (dem.crs != dst.crs):\n",
    "        reprojected_dem = np.zeros((hls.shape[1], hls.shape[2]), dtype=hls.dtype)\n",
    "        reproject(\n",
    "            source=dem.read(),\n",
    "            destination=reprojected_dem,\n",
    "            src_transform=dem.transform,\n",
    "            src_crs=dem.crs,\n",
    "            dst_transform=dst.transform,\n",
    "            dst_crs=dst.crs,\n",
    "            resampling=Resampling.bilinear)\n",
    "    hls_flat = np.squeeze(hls, axis=0)   \n",
    "\n",
    "if reprojected_dem.any():\n",
    "    struct = cp.ones((5,5))\n",
    "    reprojected_dem_gpu = cp.asarray(reprojected_dem)\n",
    "    land_mask = binary_dilation(reprojected_dem_gpu > 0, structure = struct)\n",
    "    land_mask = cp.asnumpy(land_mask)\n",
    "    # ocean_mask = binary_dilation(reprojected_dem < -60 , structure = struct)\n",
    "    # full_mask = land_mask + ocean_mask\n",
    "    \n",
    "    if(show_image):\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(land_mask, cmap='gray')\n",
    "        plt.show()    \n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"Something failed, you better go check...\")\n",
    "    sys.exit()\n",
    "\n",
    "### ==================== Load RF Classifier ================== ###\n",
    "\n",
    "with open(rf_path, 'rb') as f:\n",
    "    cu_rf = pickle.load(f)\n",
    "\n",
    "def calculate_local_variance(image_gpu, window_size):\n",
    "\n",
    "    mean_kernel = cp.ones((window_size, window_size), dtype=cp.float32) / (window_size * window_size)\n",
    "    local_mean_gpu = convolve(image_gpu.astype(cp.float32), mean_kernel, mode='constant', cval=0.0)\n",
    "\n",
    "    squared_image_gpu = cp.square(image_gpu.astype(cp.float32))\n",
    "    mean_squared_gpu = convolve(squared_image_gpu, mean_kernel, mode='constant', cval=0.0)\n",
    "    local_variance_gpu = mean_squared_gpu - cp.square(local_mean_gpu)\n",
    "    \n",
    "    return local_variance_gpu\n",
    "\n",
    "### ====================  Begin processing each file  ====================  ####\n",
    "iterations = 0\n",
    "print(f\"Granules to process: {len(granules)}\")\n",
    "print(\"Img process beginning...\")\n",
    "for item in granules:\n",
    "    if os.path.isfile(os.path.join(save_to_path,tile,f'{item}_processed.tif')):\n",
    "        print(f'{item} already processed. Skipping.')\n",
    "        continue\n",
    "    if iterations > num_iterations:\n",
    "        break\n",
    "    start_time = time.time()\n",
    " ##==========Select Granule and Get File Names==========##\n",
    "\n",
    "# Check sensor type and define bands for L8 and S2\n",
    "    if os.path.isdir(os.path.join(path,item)):\n",
    "        img_path = os.path.join(path,item)\n",
    "    else:\n",
    "        continue\n",
    "    files = os.listdir(img_path)\n",
    "    file_data = item.split('.')\n",
    "    sensor = file_data[1]\n",
    "    if(sensor == 'L30'):\n",
    "        sensor_bands = ['B02','B03','B04','B05','B06','B07'] #2,3,4,5,6,7]\n",
    "    else:\n",
    "        sensor_bands = ['B02','B03','B04','B8A','B11','B12']\n",
    "    img_files = [f for f in files if re.search(pattern, f)]\n",
    "    def get_band_index(filename):\n",
    "        match = re.search(r'\\.(B\\d{2}|B8A)\\.tif$', filename)\n",
    "        if match:\n",
    "            return sensor_bands.index(match.group(1))\n",
    "        return -1\n",
    "    pattern = re.compile(r'\\.(' + '|'.join(sensor_bands) + r')\\.tif$')\n",
    "    try:\n",
    "        img_files = sorted(img_files, key=get_band_index)\n",
    "    except:\n",
    "        print(\"failed to sort filenames\")\n",
    "        continue\n",
    "    f_mask = [f for f in files if re.search(r'Fmask\\.tif$', f)]\n",
    "    if not f_mask:\n",
    "        print(f\"Invalid granule: {item}\")\n",
    "        continue\n",
    "    if not len(img_files)  == 6:\n",
    "        print(f\"incomplete file download: {item}\")\n",
    "        continue\n",
    "\n",
    "    img_bands = []\n",
    "    metadata =[]\n",
    "    metadata_file = [f for f in files if re.search(r'metadata\\.csv$', f)]\n",
    "    if metadata_file :\n",
    "        with open(os.path.join(path,item, metadata_file[0]), mode='r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            keys = next(csv_reader)  \n",
    "            values = next(csv_reader) \n",
    "        metadata = dict(zip(keys, values)) #Load metadata into dictionary \n",
    "\n",
    "\n",
    "##==========Fmask Cloud mask==========##\n",
    "    #bitwise operations are weird. Far outside my comfort zone. Need to take CS33 first.........\n",
    "    try:\n",
    "        with rasterio.open(os.path.join(img_path,f_mask[0])) as fmask:\n",
    "            qa_band = fmask.read(1)\n",
    "        qa_bit = (1 << 1) - 1\n",
    "        qa_cloud_mask = ((qa_band >> 1) & qa_bit) == 1  # Bit 1 for cloud\n",
    "        qa_adjacent_to_cloud_mask = ((qa_band >> 2) & qa_bit) == 1  # Bit 2 for cloud adjacent\n",
    "        qa_cloud_shadow = ((qa_band >> 3) & qa_bit) == 1 \n",
    "        qa_ice = ((qa_band >> 4) & qa_bit) == 1 \n",
    "        #qa_water = ((qa_band >> 5) & qa_bit) == 1\n",
    "        qa_aerosol = (((qa_band >> 6) & 1) == 1) & (((qa_band >> 7) & 1) == 1)\n",
    "        cloud_mask = qa_cloud_mask | qa_adjacent_to_cloud_mask | qa_cloud_shadow | qa_ice | qa_aerosol#Mask out Clouds and cloud-adjacent pixels \n",
    "        cloud_mask_2D = cloud_mask.reshape(-1).T\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Error reading file {file} in granule {item}: {e}\")\n",
    "        continue  # Skip to the next granule if a file cannot be read\n",
    "    #may not be necessary to mask out the cloud-adjacent pixels \n",
    "\n",
    "##========== Determine percentage of ocean covered by clouds ==========##\n",
    "    cloud_land_mask = cloud_mask | land_mask\n",
    "    cloud_but_not_land_mask = cloud_mask & ~land_mask\n",
    "    num_pixels_cloud_not_land = np.count_nonzero(cloud_but_not_land_mask)\n",
    "    num_pixels_not_land = np.count_nonzero(~land_mask)\n",
    "    percent_cloud_covered = num_pixels_cloud_not_land/num_pixels_not_land\n",
    "    if(percent_cloud_covered > cloud_cover_threshold):\n",
    "        print(f'Granule {item} cloud cover greater than threshold. Skipping: {percent_cloud_covered}')\n",
    "        continue\n",
    "    print(f'{granule} Percent cloud covered: {percent_cloud_covered}')\n",
    "    \n",
    " ##==========Create stacked np array, Apply landmask==========##\n",
    "    try:\n",
    "        for file in img_files:\n",
    "            with rasterio.open(os.path.join(img_path, file)) as src:\n",
    "                img_bands.append(np.where(cloud_land_mask, 0, src.read(1)))  # Create image with the various bands\n",
    "    except RasterioIOError as e:\n",
    "        print(f\"Error reading file {file} in granule {item}: {e}\")\n",
    "        continue  # Skip to the next granule if a file cannot be read\n",
    "    img = np.stack(img_bands, axis=0)\n",
    "    n_bands, height, width = img.shape\n",
    "    img_2D = img.reshape(img.shape[0], -1).T #classifier takes 2D array of band values for each pixel \n",
    "\n",
    "\n",
    " ##========== Normalize multi-spectral data ==========##\n",
    "\n",
    "    img_sum = img_2D.sum(axis=1)\n",
    "    epsilon = 1e-10  \n",
    "    img_2D_nor = np.divide(img_2D, img_sum[:, None] + epsilon, where=(img_sum[:, None] != 0))\n",
    "    img_2D_nor = (img_2D_nor * 255).astype(np.uint8)\n",
    "\n",
    "    #img_data= file_img.reshape(file_img.shape[0], -1).T\n",
    "    print(img_2D_nor.shape)\n",
    "    img_data = cudf.DataFrame(img_2D_nor)\n",
    "    img_data = img_data.astype(np.float32)\n",
    "\n",
    "\n",
    "    kelp_pred = cu_rf.predict(img_data)\n",
    "    classified_img = kelp_pred.values_host.reshape(width,height)\n",
    "\n",
    "\n",
    "\n",
    "# Kelp and ocean filtering coefficients \n",
    "    ocean_dilation = cp.ones((100, 100))  # Struct for dilation (increase to enlarge non-ocean mask) larger --> takes longer\n",
    "    kelp_neighborhood = 5\n",
    "    min_kelp_count = 4\n",
    "    kelp_dilation_size = 15\n",
    "    num_EM = 30\n",
    "    variance_window_size = 15\n",
    "    variance_threshold = .95\n",
    "    structuring_element = cp.ones((kelp_dilation_size, kelp_dilation_size))\n",
    "\n",
    "    time_st = time.time()\n",
    "    classified_img_gpu = cp.array(classified_img)\n",
    "\n",
    "    kelp_mask = []\n",
    "    ocean_mask = []\n",
    "\n",
    "    time_val = time.time()\n",
    "    land_dilated_gpu = cp.where(classified_img_gpu == 3, True, False)\n",
    "    clouds_dilated_gpu = cp.where(classified_img_gpu == 2, True, False)\n",
    "    land_dilated_gpu = binary_dilation(land_dilated_gpu, structure=ocean_dilation)\n",
    "    print(f'land finished: {time.time()-time_val}')\n",
    "\n",
    "    ocean_dilated_gpu = land_dilated_gpu | clouds_dilated_gpu \n",
    "\n",
    "    def count_true(window):\n",
    "        return cp.sum(window)\n",
    "\n",
    "    kelp_dilated_gpu = cp.where(classified_img_gpu == 0, True, False)  # This is expanding the kelp_mask so the TF is reversed\n",
    "    kernel = cp.ones((kelp_neighborhood, kelp_neighborhood), dtype=cp.int32)\n",
    "\n",
    "    time_val = time.time()\n",
    "    kelp_count_gpu = convolve(kelp_dilated_gpu.astype(cp.int32), kernel, mode='constant', cval=0.0)\n",
    "    print(f'kelp moving average finished: {time.time()-time_val}')\n",
    "\n",
    "    kelp_dilated_gpu = cp.where(((~kelp_dilated_gpu) | (kelp_count_gpu <= min_kelp_count)), 0, 1)  # If there's no kelp, or the kelp count is <=4, set pixel == false\n",
    "    time_val = time.time()\n",
    "    kelp_dilated_gpu = binary_dilation(kelp_dilated_gpu, structure=structuring_element)  # I may not want to do this. we'll see\n",
    "    print(f'kelp dilation finished: {time.time()-time_val}')\n",
    "    time_val = time.time()\n",
    "    for i in range(4):\n",
    "        band_data = img[i ]\n",
    "        band_data_gpu = cp.array(band_data)\n",
    "        \n",
    "        kmask_gpu = cp.where(kelp_dilated_gpu == 1, band_data_gpu, cp.nan)\n",
    "        omask_gpu = cp.where((ocean_dilated_gpu == False), band_data_gpu, cp.nan)\n",
    "\n",
    "\n",
    "        local_variance_gpu = calculate_local_variance(band_data_gpu, variance_window_size)\n",
    "        max_local_variance = cp.percentile(local_variance_gpu, 100 * variance_threshold)  # threshold variance\n",
    "        \n",
    "        # Mask pixels with high variance\n",
    "        variance_mask_gpu = cp.where(local_variance_gpu > max_local_variance, cp.nan, band_data_gpu)\n",
    "        \n",
    "        # Apply the variance mask to the ocean mask\n",
    "        final_omask_gpu = cp.where((ocean_dilated_gpu == True) | cp.isnan(variance_mask_gpu) , cp.nan, band_data_gpu)\n",
    "        \n",
    "\n",
    "        #kmask = cp.asnumpy(kmask_gpu)\n",
    "        #omask = cp.asnumpy(final_omask_gpu)\n",
    "        \n",
    "        kelp_mask.append(kmask)\n",
    "        ocean_mask.append(omask)\n",
    "    print(f'kBand masking and variance masking complete: {time.time()-time_val}')\n",
    "    kelp_mask = cp.array(kelp_mask)\n",
    "    ocean_mask = cp.array(ocean_mask)\n",
    "\n",
    "\n",
    "        #print(ocean_mask)\n",
    "\n",
    "    rgb_nor = cp.stack([ocean_mask[2]/600,ocean_mask[0]/600,ocean_mask[1]/600], axis=-1)\n",
    "    rgb_nor_cropped = rgb_nor\n",
    "    #print(kelp_mask)\n",
    "    rgb_nor_cropped = cp.ma.masked_where(np.isnan(rgb_nor_cropped), rgb_nor_cropped)\n",
    "    rgb_cpu = cp.asnumpy(rgb_nor_cropped)\n",
    "    image = kelp_mask[1]#,2500:3500,800:1800]\n",
    "    \n",
    "    del rgb_nor_cropped, rgb_nor\n",
    "\n",
    "    plt.figure(figsize=(30, 30), dpi=200)\n",
    "    plt.imshow(image, alpha=1)\n",
    "    plt.imshow(rgb_cpu, alpha=1)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    ocean_EM_stack = []\n",
    "    kelp_EM = [459, 556, 437, 1227]\n",
    "\n",
    "    n_bands, height, width = kelp_mask.shape\n",
    "    ocean_EM_n = 0\n",
    "    ocean_data = ocean_mask.reshape(ocean_mask.shape[0], -1)\n",
    "    kelp_data = kelp_mask.reshape(kelp_mask.shape[0],-1)\n",
    "\n",
    "    nan_columns = cp.isnan(ocean_data).any(axis=0)  # Remove columns with nan \n",
    "   \n",
    "    filtered_ocean = ocean_data[:, ~nan_columns]\n",
    "    # if len(filtered_ocean[0,:]) < 500:\n",
    "    #     print(\"Too few valid ocean end-members\")\n",
    "    #     print(f\"Skipping img {file}...  :(\")\n",
    "    #     continue\n",
    "    for i in range(30):\n",
    "        index = random.randint(0,len(filtered_ocean[0])-1)\n",
    "        ocean_EM_stack.append(filtered_ocean[:,index])\n",
    "    ocean_EM = cp.stack(ocean_EM_stack, axis=1)\n",
    "    #print(ocean_EM_array)\n",
    "\n",
    "    average_val = np.nanmean(filtered_ocean, axis=1)\n",
    "    average_endmember = np.nanmean(ocean_EM, axis=1)\n",
    "    print(f\"average EM Val: {average_endmember}\")\n",
    "    print(f\"average    Val: {average_val}\")\n",
    "\n",
    "    kelp_mask = cp.asarray(kelp_mask)\n",
    "    ocean_EM = cp.asarray(ocean_EM)\n",
    "    kelp_EM = cp.asarray(kelp_EM)\n",
    "    kelp_data = cp.asarray(kelp_data)\n",
    "\n",
    "    frac1 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    frac2 = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    rmse = cp.full((kelp_mask.shape[1], kelp_mask.shape[2], 30), cp.nan)\n",
    "    print(rmse.shape)\n",
    "\n",
    "    print(\"Running MESMA\")\n",
    "    for k in range(30):\n",
    "        B = cp.column_stack((ocean_EM[:, k], kelp_EM))\n",
    "        U, S, Vt = cp.linalg.svd(B, full_matrices=False)\n",
    "        IS = Vt.T / S\n",
    "        em_inv = IS @ U.T\n",
    "        F = em_inv @ kelp_data\n",
    "        model = (F.T @ B.T).T\n",
    "        resids = (kelp_data - model) / 10000\n",
    "        rmse[:, :, k] = cp.sqrt(cp.mean(resids**2, axis=0)).reshape(height, width)\n",
    "        frac1[:, :, k] = F[0, :].reshape(height, width)\n",
    "        frac2[:, :, k] = F[1, :].reshape(height, width)\n",
    "\n",
    "\n",
    "        data_type = rasterio.int16\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'count': 5,  # one band  B02, B03, B04, and B05, classified (Blue, Green, Red, and NIR).\n",
    "            'dtype': data_type,  # assuming binary mask, adjust dtype if needed\n",
    "            'crs': src.crs,\n",
    "            'transform': src.transform,\n",
    "            'nodata': 0  # assuming no data is 0\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "    minVals = cp.nanmin(rmse, axis=2)\n",
    "    PageIdx = cp.nanargmin(rmse, axis=2)\n",
    "    rows, cols = cp.meshgrid(cp.arange(rmse.shape[0]), cp.arange(rmse.shape[1]), indexing='ij')\n",
    "    Zindex = cp.ravel_multi_index((rows, cols, PageIdx), dims=rmse.shape)\n",
    "    Mes2 = frac2.ravel()[Zindex]\n",
    "    Mes2 = Mes2.T\n",
    "    Mes2 = -0.229 * Mes2**2 + 1.449 * Mes2 - 0.018 #Landsat mesma corrections \n",
    "    Mes2 = cp.clip(Mes2, 0, None)  # Ensure no negative values\n",
    "    Mes2 = cp.round(Mes2 * 100).astype(cp.int16)\n",
    "\n",
    "\n",
    "    #Mes2 = Mes2.astype(cp.float32)\n",
    "    #Mes2 = Mes2.where(Mes2 == 0, cp.nan)\n",
    "    Mes_array = cp.asnumpy(Mes2).T\n",
    "    if show_image:\n",
    "        kelp_img = cp.asnumpy(kelp_mask).astype(np.float32)\n",
    "        Mes_array = cp.asnumpy(Mes2).T\n",
    "        Mes_array_vis = np.where(Mes_array == 0, np.nan, Mes_array)\n",
    "        kelp_vis = np.where(kelp_img == 0, np.nan, kelp_img)\n",
    "        plt.figure(figsize=(20, 20), dpi=200)\n",
    "        plt.imshow(rgb_nor[1,2800:3100,800:1400], alpha=1)\n",
    "        plt.imshow(kelp_img[1,2800:3100,800:1400] , cmap='Greys', alpha=1)\n",
    "        plt.imshow(Mes_array_vis[2800:3100,800:1400], alpha=1)\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    \n",
    "    #  ##========== Save masked file ==========##\n",
    "\n",
    "    if save_final_data:\n",
    "        num_bands = 6\n",
    "        data_type = rasterio.int16\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'count': 6,  # one band  B02, B03, B04, and B05, classified (Blue, Green, Red, and NIR).\n",
    "            'dtype': data_type,  # assuming binary mask, adjust dtype if needed\n",
    "            'crs': src.crs,\n",
    "            'transform': src.transform,\n",
    "            'nodata': 0  # assuming no data is 0\n",
    "        }\n",
    "        if not os.path.isdir(os.path.join(save_to_path,tile)):\n",
    "            os.mkdir(os.path.join(save_to_path,tile))\n",
    "        img_path = os.path.join(save_to_path,tile,f'{item}_processed.tif')\n",
    "\n",
    "        # Write the land mask array to GeoTIFF\n",
    "        with rasterio.open(img_path, 'w', **profile) as dst:\n",
    "                dst.write(img[0].astype(data_type), 1)\n",
    "                dst.write(img[1].astype(data_type), 2)\n",
    "                dst.write(img[2].astype(data_type), 3)\n",
    "                dst.write(img[3].astype(data_type), 4)\n",
    "                dst.write(classified_img.astype(data_type), 5)\n",
    "                dst.write(Mes_array.astype(data_type), 6)\n",
    "                \n",
    "        iterations = iterations + 1\n",
    "        print(f\"Iteration: {iterations}\")\n",
    "    gc.collect()\n",
    "    print(f\"{item} Processing complete. Duration: {time.time()-start_time}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-24.06",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
